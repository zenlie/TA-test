{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f19661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f190c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>transalted</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>punct</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Indonesia Close the entrance for this country ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>Indonesia Close the entrance for this country ...</td>\n",
       "      <td>['indonesia', 'close', 'the', 'entrance', 'for...</td>\n",
       "      <td>['indonesia', 'close', 'entrance', 'country', ...</td>\n",
       "      <td>['indonesia', 'close', 'entranc', 'countri', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which country is prohibited by Indonesia Berit...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Which country is prohibited by Indonesia Berit...</td>\n",
       "      <td>['which', 'country', 'is', 'prohibited', 'by',...</td>\n",
       "      <td>['country', 'prohibited', 'indonesia', 'berita...</td>\n",
       "      <td>['countri', 'prohibit', 'indonesia', 'beritaci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What are the unusual symptoms Omicron BeritaCi...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>What are the unusual symptoms Omicron BeritaCi...</td>\n",
       "      <td>['what', 'are', 'the', 'unusual', 'symptoms', ...</td>\n",
       "      <td>['unusual', 'symptoms', 'omicron', 'beritacini...</td>\n",
       "      <td>['unusu', 'symptom', 'omicron', 'beritacini', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sange ni vcs yuk anyone who wants to accompany...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sange ni vcs yuk anyone who wants to accompany...</td>\n",
       "      <td>['sange', 'ni', 'vcs', 'yuk', 'anyone', 'who',...</td>\n",
       "      <td>['sange', 'ni', 'vcs', 'yuk', 'anyone', 'wants...</td>\n",
       "      <td>['sang', 'ni', 'vc', 'yuk', 'anyon', 'want', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Albert Informative Land Fertile But Life Doesn...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Albert Informative Land Fertile But Life Doesn...</td>\n",
       "      <td>['albert', 'informative', 'land', 'fertile', '...</td>\n",
       "      <td>['albert', 'informative', 'land', 'fertile', '...</td>\n",
       "      <td>['albert', 'inform', 'land', 'fertil', 'life',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2171</td>\n",
       "      <td>The government plans to provide BSU subsidy as...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>The government plans to provide BSU subsidy as...</td>\n",
       "      <td>['the', 'government', 'plans', 'to', 'provide'...</td>\n",
       "      <td>['government', 'plans', 'provide', 'bsu', 'sub...</td>\n",
       "      <td>['govern', 'plan', 'provid', 'bsu', 'subsidi',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2172</td>\n",
       "      <td>ahead of the Christmas and New Year holidays 2...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>ahead of the Christmas and New Year holidays  ...</td>\n",
       "      <td>['ahead', 'of', 'the', 'christmas', 'and', 'ne...</td>\n",
       "      <td>['ahead', 'christmas', 'new', 'year', 'holiday...</td>\n",
       "      <td>['ahead', 'christma', 'new', 'year', 'holiday'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>2173</td>\n",
       "      <td>When Schoolkite Go to Unicorn Valuation of the...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>When Schoolkite Go to Unicorn Valuation of the...</td>\n",
       "      <td>['when', 'schoolkite', 'go', 'to', 'unicorn', ...</td>\n",
       "      <td>['schoolkite', 'go', 'unicorn', 'valuation', '...</td>\n",
       "      <td>['schoolkit', 'go', 'unicorn', 'valuat', 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>2174</td>\n",
       "      <td>Regent targets this week Kendal Level 1 Covid ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Regent targets this week Kendal Level  Covid  ...</td>\n",
       "      <td>['regent', 'targets', 'this', 'week', 'kendal'...</td>\n",
       "      <td>['regent', 'targets', 'week', 'kendal', 'level...</td>\n",
       "      <td>['regent', 'target', 'week', 'kendal', 'level'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>2175</td>\n",
       "      <td>The issue of all transportation will be instru...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The issue of all transportation will be instru...</td>\n",
       "      <td>['the', 'issue', 'of', 'all', 'transportation'...</td>\n",
       "      <td>['issue', 'transportation', 'instructed', 'res...</td>\n",
       "      <td>['issu', 'transport', 'instruct', 'result', 'p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2176 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                         transalted  polarity  \\\n",
       "0              0  Indonesia Close the entrance for this country ...  0.000000   \n",
       "1              1  Which country is prohibited by Indonesia Berit...  0.000000   \n",
       "2              2  What are the unusual symptoms Omicron BeritaCi...  0.200000   \n",
       "3              3  sange ni vcs yuk anyone who wants to accompany...  0.200000   \n",
       "4              4  Albert Informative Land Fertile But Life Doesn...  0.000000   \n",
       "...          ...                                                ...       ...   \n",
       "2171        2171  The government plans to provide BSU subsidy as...  0.000000   \n",
       "2172        2172  ahead of the Christmas and New Year holidays 2...  0.090909   \n",
       "2173        2173  When Schoolkite Go to Unicorn Valuation of the...  0.000000   \n",
       "2174        2174  Regent targets this week Kendal Level 1 Covid ...  0.000000   \n",
       "2175        2175  The issue of all transportation will be instru...  0.000000   \n",
       "\n",
       "      subjectivity sentiment  label    neg    pos  compound  \\\n",
       "0         0.000000  positive      1  0.000  0.098    0.4278   \n",
       "1         0.000000  positive      1  0.000  0.000    0.0000   \n",
       "2         1.000000  positive      1  0.000  0.000    0.0000   \n",
       "3         0.100000  positive      1  0.000  0.000    0.0000   \n",
       "4         0.000000  positive      1  0.000  0.000    0.0000   \n",
       "...            ...       ...    ...    ...    ...       ...   \n",
       "2171      0.000000  negative      0  0.082  0.000   -0.1531   \n",
       "2172      0.511364  positive      1  0.000  0.129    0.6369   \n",
       "2173      0.000000  positive      1  0.000  0.037    0.0258   \n",
       "2174      0.000000  positive      1  0.000  0.000    0.0000   \n",
       "2175      0.000000  positive      1  0.000  0.000    0.0000   \n",
       "\n",
       "                                                  punct  \\\n",
       "0     Indonesia Close the entrance for this country ...   \n",
       "1     Which country is prohibited by Indonesia Berit...   \n",
       "2     What are the unusual symptoms Omicron BeritaCi...   \n",
       "3     sange ni vcs yuk anyone who wants to accompany...   \n",
       "4     Albert Informative Land Fertile But Life Doesn...   \n",
       "...                                                 ...   \n",
       "2171  The government plans to provide BSU subsidy as...   \n",
       "2172  ahead of the Christmas and New Year holidays  ...   \n",
       "2173  When Schoolkite Go to Unicorn Valuation of the...   \n",
       "2174  Regent targets this week Kendal Level  Covid  ...   \n",
       "2175  The issue of all transportation will be instru...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "0     ['indonesia', 'close', 'the', 'entrance', 'for...   \n",
       "1     ['which', 'country', 'is', 'prohibited', 'by',...   \n",
       "2     ['what', 'are', 'the', 'unusual', 'symptoms', ...   \n",
       "3     ['sange', 'ni', 'vcs', 'yuk', 'anyone', 'who',...   \n",
       "4     ['albert', 'informative', 'land', 'fertile', '...   \n",
       "...                                                 ...   \n",
       "2171  ['the', 'government', 'plans', 'to', 'provide'...   \n",
       "2172  ['ahead', 'of', 'the', 'christmas', 'and', 'ne...   \n",
       "2173  ['when', 'schoolkite', 'go', 'to', 'unicorn', ...   \n",
       "2174  ['regent', 'targets', 'this', 'week', 'kendal'...   \n",
       "2175  ['the', 'issue', 'of', 'all', 'transportation'...   \n",
       "\n",
       "                                                nonstop  \\\n",
       "0     ['indonesia', 'close', 'entrance', 'country', ...   \n",
       "1     ['country', 'prohibited', 'indonesia', 'berita...   \n",
       "2     ['unusual', 'symptoms', 'omicron', 'beritacini...   \n",
       "3     ['sange', 'ni', 'vcs', 'yuk', 'anyone', 'wants...   \n",
       "4     ['albert', 'informative', 'land', 'fertile', '...   \n",
       "...                                                 ...   \n",
       "2171  ['government', 'plans', 'provide', 'bsu', 'sub...   \n",
       "2172  ['ahead', 'christmas', 'new', 'year', 'holiday...   \n",
       "2173  ['schoolkite', 'go', 'unicorn', 'valuation', '...   \n",
       "2174  ['regent', 'targets', 'week', 'kendal', 'level...   \n",
       "2175  ['issue', 'transportation', 'instructed', 'res...   \n",
       "\n",
       "                                                stemmed  \n",
       "0     ['indonesia', 'close', 'entranc', 'countri', '...  \n",
       "1     ['countri', 'prohibit', 'indonesia', 'beritaci...  \n",
       "2     ['unusu', 'symptom', 'omicron', 'beritacini', ...  \n",
       "3     ['sang', 'ni', 'vc', 'yuk', 'anyon', 'want', '...  \n",
       "4     ['albert', 'inform', 'land', 'fertil', 'life',...  \n",
       "...                                                 ...  \n",
       "2171  ['govern', 'plan', 'provid', 'bsu', 'subsidi',...  \n",
       "2172  ['ahead', 'christma', 'new', 'year', 'holiday'...  \n",
       "2173  ['schoolkit', 'go', 'unicorn', 'valuat', 'comp...  \n",
       "2174  ['regent', 'target', 'week', 'kendal', 'level'...  \n",
       "2175  ['issu', 'transport', 'instruct', 'result', 'p...  \n",
       "\n",
       "[2176 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "df = pd.read_csv('Dataset_Processing.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7d82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703e6904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size :  (1740, 13)\n",
      "Test data size :  (436, 13)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "print(\"Training data size : \", train_df.shape)\n",
    "print(\"Test data size : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d338dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa67c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 10000\n",
    "tokenizer = Tokenizer(num_words=top_words)\n",
    "tokenizer.fit_on_texts(train_df['transalted'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(train_df['transalted'])\n",
    "\n",
    "max_review_length = 200\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen=max_review_length)\n",
    "y_train = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61ec1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1998\n",
       "negative     178\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3b50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding , LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25384033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 32)           320032    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               53200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 373,333\n",
      "Trainable params: 373,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff2a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22/22 [==============================] - 11s 371ms/step - loss: 0.4319 - accuracy: 0.9138 - val_loss: 0.2979 - val_accuracy: 0.9109\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 7s 333ms/step - loss: 0.2765 - accuracy: 0.9203 - val_loss: 0.3005 - val_accuracy: 0.9109\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 7s 327ms/step - loss: 0.2704 - accuracy: 0.9203 - val_loss: 0.2915 - val_accuracy: 0.9109\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 7s 314ms/step - loss: 0.2451 - accuracy: 0.9203 - val_loss: 0.2568 - val_accuracy: 0.9109\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 7s 329ms/step - loss: 0.1864 - accuracy: 0.9296 - val_loss: 0.2570 - val_accuracy: 0.9195\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 7s 322ms/step - loss: 0.1080 - accuracy: 0.9634 - val_loss: 0.1930 - val_accuracy: 0.9224\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 8s 345ms/step - loss: 0.0914 - accuracy: 0.9662 - val_loss: 0.2102 - val_accuracy: 0.9282\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 7s 338ms/step - loss: 0.0846 - accuracy: 0.9705 - val_loss: 0.2510 - val_accuracy: 0.9253\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 7s 329ms/step - loss: 0.0591 - accuracy: 0.9770 - val_loss: 0.2635 - val_accuracy: 0.9368\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 7s 320ms/step - loss: 0.0420 - accuracy: 0.9914 - val_loss: 0.2336 - val_accuracy: 0.9339\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 7s 326ms/step - loss: 0.0321 - accuracy: 0.9964 - val_loss: 0.2765 - val_accuracy: 0.9368\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 7s 329ms/step - loss: 0.0195 - accuracy: 0.9971 - val_loss: 0.2273 - val_accuracy: 0.9138\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 7s 327ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.2432 - val_accuracy: 0.9282\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 8s 344ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 0.2733 - val_accuracy: 0.9397\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 7s 335ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.3661 - val_accuracy: 0.9339\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 8s 355ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.2798 - val_accuracy: 0.9368\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 8s 357ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.2910 - val_accuracy: 0.9397\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 9s 387ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.2748 - val_accuracy: 0.9368\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 8s 364ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.2983 - val_accuracy: 0.9339\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 8s 381ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.2609 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f57979ae50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=20, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a719209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model :  0.9174311926605505\n",
      "F1-score:  0.9569377990430622\n",
      "precision_score:  1.0\n",
      "recall_score:  0.9174311926605505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,recall_score, precision_score\n",
    "\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(test_df['sentiment'])\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen=max_review_length)\n",
    "y_test = test_df['label']\n",
    "prediction = model.predict(X_test)\n",
    "y_pred = (prediction > 0.5)\n",
    "#print(y_pred)\n",
    "#print(y_test)\n",
    "print(\"Accuracy of the model : \", accuracy_score(y_pred, y_test))\n",
    "print('F1-score: ', f1_score(y_pred, y_test))\n",
    "print('precision_score: ', precision_score(y_pred, y_test))\n",
    "print('recall_score: ', recall_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59addc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
